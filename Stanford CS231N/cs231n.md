# Lecture 2: Image Classification with Linear Classifiers

对于图片分类问题，与其对每种类型的图像都硬编码，使用大量的if else来穷举类型的特征，深度学习使用的方法是**数据驱动**的方式，给机器提供每种类型大量的图片，然后学习出一个算法能够识别这些类别

## Nearest Neighbor Classifier

我们使用cifar-10作为数据集，这个数据集有十种类别的60000张图片组成，每张图片32个像素长和宽

下图中左边是训练集的类别和对应的图片，右边是测试时，给出一张没见过的图片，根据最近邻算法（对比两张图片像素级的差别）从训练集中找出的最相似的十张图片，最近邻算法会将其中最相似的一张图片的label作为预测的结果

![image-20230910215444888](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230910215444888.png)

对比两张图片相似度的具体方法：L1算法：

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230910220236429.png" alt="image-20230910220236429" style="zoom:67%;" />

![image-20230910220319688](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230910220319688.png)

但是这个做法是准确率是极低的（**38.6%**）

除了L1之外，还有L2算法来对比图片的相似度。与L1唯一的区别就是对每个元素的差距平方求和后再取平方根（在实际的最近邻算法中取平方根是不必要的，因为它虽然改变了数值，但是不改变结果之间的排序）

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230910222218547.png" alt="image-20230910222218547" style="zoom:67%;" />

L1和L2的区别就在于，对于有多个小差距的元素的图片L1的值更高，对于有一个大差距元素的图片，L2的值更高

最近邻算法的实际实现是在训练时直接把所有数据存起来，然后在测试时将输入图片与训练的图片一一对比

## k - Nearest Neighbor Classifier

使用top K的最近邻，K的值越高，则分类器对异常值的抵抗力越强

最近邻算法可以用于学习决策边界，基于训练数据，将这些数据点分开

在NN分类器中，在红色的点中出现一个绿色的点会导致红色的类别中出现一个孤岛，导致预测出错

![image-20230911140400721](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911140400721.png)

显然，最近邻算法的缺点在于：它在训练时很快，但是在测试时非常非常慢。而我们大部分的深度学习算法都是在训练时非常非常慢，在测试时很快

并且最近邻算法在图片分类中并不是一个好的选择，因为图片是高维的物体（包含很多像素），但是**在高维空间上L2算法的距离与我们实际上感知的相似度是不一样的**。

最左边的图片是原图，右边的三张图片与原图的L2距离是一样的，但是很显然这并不能代表这三张图片与原图的相似度

![image-20230911143129795](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911143129795.png)

并且很多时候**距离反应更多的是两张图片的背景和颜色分布，而不是语意内容**。我们期望同种的东西可以被分类到一起，不管图片中无关的特性和变量（比如背景）

如果在实际中要使用KNN，我们应该在验证集上调整出最好的K

## Linear Classification

![image-20230911154951352](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911154951352.png)

W的每一行负责识别一个种类，对应一个分类模版，**一行中的每一个参数代表图片中的这个像素（的颜色）对这一行的分类有多少影响**，例如，你可以想象，如果图像的下面有很多蓝色（可能对应于水），那么“船”类的可能性可能更大。所以“船舶”分类器在其蓝色channel的像素的权重会更大（蓝色的存在会增加船舶的分数），而在红色/绿色channel中权重会更小（红色/绿色的存在会降低船舶的得分）

bias不与输入数据产生互动，只会给我们一些数据独立的、针对某一类的偏好值，如果我们的数据集是不平衡的（比如猫的数量多于狗），那么猫所对应的bias就会比其他的高

我们也可以把参数W解释为模式匹配，W的每一行对应每一类的模式，**和最近邻算法一样，测试时一张图片在某个类别上的分数是用该图片与W中该类别对应的模式（即某一行）进行对比得到的**，只不过最近邻算法的图片对比使用的是L2距离，而**线性分类采用的是内积**，并且这里的匹配的模式不需要出现在训练集的图片中

下图是在训练结束后得到的权重中的**每一类的模式reshape成图片的形状后的样子**，可以看到ship类的模式包含大量的蓝色的像素，所以一旦测试的图片中包含大量蓝色的像素，那么ship类的预测值就会很高

![image-20230911203637631](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911203637631.png)

并且horse类似乎有一个双头的horse，这是因为在数据集中面向左边和右边的horse都存在，所以分类器将这两种horse的模式融合到了一起，这样不管出现面向哪边的horse都能匹配上

car的模式是红色的，因为数据集中红色车的数量远多于其他的颜色。

线性分类器太弱了，无法检测不同颜色的汽车，但是神经网络可以，它通过中间的神经元能够检测特定的汽车类型，并且下一层的神经元可以通过将上一层的神经元的加权和，将他们的模式结合起来，得到更精确的分数

**Bias trick.**

![image-20230911205442179](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911205442179.png)

我们只需要在所有的输入向量后加上一个常数1，再将原来的bias作为一列加到W的最右边，就能将加上bias融入Wx。所以，如果我们这样预处理数据，那么就从原来需要计算两个矩阵（W和bias）变成只需要计算一个矩阵了

### Multiclass Support Vector Machine loss

SVM Loss**希望正确类别的预测得分比错误类别的得分高出一个固定的值Δ**，具体公式是：i是输入的example，j是第j个类别，yi是该example正确类别的下标，S是某个类别的预测结果

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911170611243.png" alt="image-20230911170611243" style="zoom:67%;" />

![image-20230911172108627](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911172108627.png)

![image-20230911172122620](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911172122620.png)

![image-20230911172140073](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911172140073.png)

如果其他错误标签对应的score超过了一定的阈值(即超过了<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913190340605.png" alt="image-20230913190340605" style="zoom:50%;" />)，就需要累加到损失函数上面，因为我们总是希望正确标签的score大而错误标签的score比较小，因此设置了一个阈值(一般选择1作为阈值)作为判断错误标签的score是否过大的依据

所以正确类别的预测结果要尽可能地高于蓝线：

![image-20230911171621125](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911171621125.png)

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911172320717.png" alt="image-20230911172320717" style="zoom:67%;" />

SVM Loss的最小值是0，最大值是无穷大；W刚初始化的时候，所有的输出值都差不多，此时的Loss约等于类别的数量减去1

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911173145590.png" alt="image-20230911173145590" style="zoom:67%;" />

### Softmax classifier

![image-20230911190919838](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911190919838.png)

SVM超过一个阈值之后Loss就不会再积累，而softmax不管正确类别的预测结果和其他类别的预测结果差距多大都不满足，总是期望正确的结果更大，错误的结果更低

由于Loss是数据集所有example的Loss的平均值，所以不建议一次性计算整个数据集，而是随机分成小批量计算

![image-20230911192602461](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230911192602461.png)

## Assignment1

### KNN的实现

#### 计算距离矩阵：向量化的好处

我们需要计算输入的点和训练集中的点之间的L2距离，我们假设训练集是N*D维度的，即N个数据，每个数据都是D维度，而测试集是M * D的，我们需要计算的就是一个M * N的距离矩阵。

我们首先用最naive的方式——二层for循环来实现距离的计算，具体的代码如下图所示：

```python
def compute_distances_two_loops(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    for i in range(num_test):
        for j in range(num_train):
  					dists[i][j] = np.sqrt(np.sum((X[i] - self.X_train[j]) ** 2))
    return dists
```

计算速度很慢，这是因为**Python中处理for循环非常耗时**，**我们应该尝试使用更多numpy提供的api直接快速计算出整个距离矩阵而不依赖于for循环**，这样就可以加快代码运行的速度，这个过程就是向量化——不是按照索引对数据一个个进行处理，而是**利用api和广播机制**，直接对所有输入数据一起进行操作，使用一个循环和不使用循环的kNN距离矩阵计算的代码实现如下：

```python
def compute_distances_one_loop(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    for i in range(num_test):
        dists[i, :] = np.sqrt(np.sum((X[i] - self.X_train) ** 2, axis=-1))
    return dists

def compute_distances_no_loops(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    dists = np.sqrt(
        np.sum(X ** 2, axis=-1).reshape(-1, 1) + np.sum(self.X_train ** 2, axis=-1) - 2 * np.matmul(X, self.X_train.T)
    )
    return dists
```

广播的规则：比较两个数组的shape，从shape的**尾部**开始一一比对。

1. 如果两个数组的维度相同，**对应位置上轴的长度相同或其中一个的轴长度为1**,广播兼容，可在轴长度为1的轴上进行广播机制处理。
2. 如果两个数组的维度不同，那么给低维度的数组**前扩展**提升一维，扩展维的轴长度为1,然后在扩展出的维上进行广播机制处理（第一步的操作）。

```python
        # 对axis=1求和，得到的是一个行向量，即(500,)和(5000,)（注意！一维的向量的形状不能写成(500)！因为(500)不是元组，只是500加个括号而已，(500,)才能算元组，才能表示一个向量的形状！
        # 想让(500,)和(5000,)广播相加，只有先把(500,)转换成(500,1)，这样二者才能相加。同时，(5000,)不能转换成(5000,1)，这样的话二者的第一维就不匹配了，无法广播
        dists = np.square(X).sum(axis=1).reshape(-1,1) + np.square(self.X_train).sum(axis=1) - 2 * np.dot(X,self.X_train.T)
```

具体的广播过程是前者先从(500,1)扩展到(500,5000)，这样和(5000,)的最后一个维度就相同了，然后再把(5000,)扩展到(1,5000)，这样二者的维度数量就相同了，然后再把(1,5000)扩展到(500,5000)，最后二者相加，得到的矩阵中每一行是一个测试与所有训练图片的距离

notebook中提供了一个简单的运行时间比较，在10000条测试数据上三个向量化程度不同的算法的时间消耗分别是：

| 向量化程度  | 两层循环  | 一层循环  | 完全向量化 |
| ----------- | --------- | --------- | ---------- |
| 运行时间(s) | 15.279955 | 29.577301 | 0.457510   |

可以看到向量化在数据量大的时候真的可以带来非常显著的性能提升。

#### 分类精度的计算

用预测的结果（一个一维向量，每个位置是一个example对应的预测类别）与正确答案进行对比，得到bool矩阵，再对其求平均值

```python
y_train_pred = svm.predict(X_train)
print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))
```

### SVM

#### svm loss和梯度的计算

在输入是多维的函数中，梯度是每个维度的偏导组成的向量。求梯度有两种方式

- 一种是缓慢、近似但是简单的方法（**numerical gradient**，即按照定义求偏导）
- 一种是快速、准确但是容易出错的方法（**analytic gradient**，即按照导数公式求导）

定义法：输入一个函数f和向量X，计算f在X上的偏导。

该做法会一个一个地遍历所有的维度，在该维度上做一个小的变化h，通过计算f的值改变了多少来算出该维度的偏导，维护一个列表grad来记录所有的维度的偏导，也就是f在X点处的梯度

```python
def eval_numerical_gradient(f, x):
  """
  a naive implementation of numerical gradient of f at x
  - f should be a function that takes a single argument
  - x is the point (numpy array) to evaluate the gradient at
  """

  fx = f(x) # evaluate function value at original point
  grad = np.zeros(x.shape)
  h = 0.00001

  # iterate over all indexes in x
  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
  while not it.finished:

    # evaluate function at x+h
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # increment by h
    fxh = f(x) # evalute f(x + h)
    x[ix] = old_value # restore to previous value (very important!)

    # compute the partial derivative
    grad[ix] = (fxh - fx) / h # the slope
    it.iternext() # step to next dimension

  return grad
```

更新参数时朝向梯度的相反方向更新，因为我们希望loss函数的值减少而不是增加

但是numerical的方法太慢了，复杂度与参数的个数成正比，现代神经网络有几千万个参数，显然这种方法是不能scalable的，我们需要更好的方法。并且它是近似的，是不准确的（因为我们没有办法对h求极限）

公式法：很快速准确，但是容易出错，所以在现实中我们通常将公式法的计算结果和定义法的计算结果进行对比，来检查我们的实现是否正确，这叫gradient check

SVM loss的函数：W是维度为10 * 3073的矩阵，X是维度为3073 * 1的向量，Wj是W中的某一行reshape成列向量，所以WjT是行向量（也就是W中的某一行）

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913184129558.png" alt="image-20230913184129558" style="zoom:67%;" />

L是一个标量，标量对向量求导得到的是一个向量（标量对矩阵求导得到的是矩阵，向量对向量求导得到的是矩阵）

所以L对Wyi求偏导的结果为：因为对Wyi求偏导，所以视其他Wj为常数（所以求导后WjX为0），又因为WyiX求偏导后得到X。所以如果<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913184953505.png" alt="image-20230913184953505" style="zoom: 33%;" />大于0，则结果是-X；如果小于0，则结果是0。所以求和之后的结果是：**与正确类别的预测结果的差距未达到margin的类的个数，乘以-X**

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913184541958.png" alt="image-20230913184541958" style="zoom:80%;" />

1表示内部的条件如果是true就是1，如果是false就是0

上面是对正确类别的参数求偏导的结果，对其他类别的参数求偏导的结果是:

对W其中的一行参数求偏导，则其他的参数都被视为常数，所以求和的公式中**只剩下一个X（在<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913185801735.png" alt="image-20230913185801735" style="zoom:33%;" />大于0的情况下，如果小于0，则连这一个X都没有了）**

![image-20230913185426238](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230913185426238.png)

使用公式法加for循环实现svm的loss和梯度：

```python
def svm_loss_naive(W, X, y, reg):
    """
    Structured SVM loss function, naive implementation (with loops).

    Inputs have dimension D, there are C classes, and we operate on minibatches
    of N examples.

    Inputs:
    - W: A numpy array of shape (D, C) containing weights.
    - X: A numpy array of shape (N, D) containing a minibatch of data.
    - y: A numpy array of shape (N,) containing training labels; y[i] = c means
      that X[i] has label c, where 0 <= c < C.
    - reg: (float) regularization strength

    Returns a tuple of:
    - loss as single float
    - gradient with respect to weights W; an array of same shape as W
    """
    dW = np.zeros(W.shape)  # initialize the gradient as zero

    # compute the loss and the gradient
    num_classes = W.shape[1]
    num_train = X.shape[0]
    loss = 0.0
    # 每一次循环都是一个example
    for i in range(num_train):
        scores = X[i].dot(W)
        correct_class_score = scores[y[i]]
        # 每次循环是一列W，即3073*1的列向量
        for j in range(num_classes):
            if j == y[i]:
                continue
            margin = scores[j] - correct_class_score + 1  # note delta = 1
            if margin > 0:
                loss += margin
                dW[:,y[i]] += -X[i]
                dW[:,j] += X[i]
    # Right now the loss is a sum over all training examples, but we want it
    # to be an average instead so we divide by num_train.
    loss /= num_train
    dW /= num_train 
    # Add regularization to the loss.
    loss += reg * np.sum(W * W)
    dW += 2 * reg * W
    return loss, dW
```

使用公式法向量化地计算svm的loss和梯度

```python
def svm_loss_vectorized(W, X, y, reg):
    """
    Structured SVM loss function, vectorized implementation.

    Inputs and outputs are the same as svm_loss_naive.
    """
    loss = 0.0
    dW = np.zeros(W.shape)  # initialize the gradient as zero
    train_num = X.shape[0]
    #############################################################################
    # TODO:                                                                     #
    # Implement a vectorized version of the structured SVM loss, storing the    #
    # result in loss.                                                           #
    #############################################################################
    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    y_predict = X.dot(W)
    true_category_pred = y_predict[range(train_num),y].reshape(-1,1)
    mask = np.ones(y_predict.shape,dtype=bool)
    mask[range(train_num),y] = False
    # false_cate_pred = y_predict[mask].reshape(500,9)
    # 行数是example的数量，每一行对应一个example的预测结果
    distance = y_predict - true_category_pred + 1
    distance = distance * mask
    mask2 = distance > 0
    # 每一行对应一个example，每个元素代表该类别与正确类别的距离（并且是与0做了max后的距离），正确类别处的值为0
    masked_distance = distance * mask2
    sum_distance = masked_distance.sum(axis=1)
    loss = sum_distance.mean()
    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    #############################################################################
    # TODO:                                                                     #
    # Implement a vectorized version of the gradient for the structured SVM     #
    # loss, storing the result in dW.                                           #
    #                                                                           #
    # Hint: Instead of computing the gradient from scratch, it may be easier    #
    # to reuse some of the intermediate values that you used to compute the     #
    # loss.                                                                     #
    #############################################################################
    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    margin = masked_distance  # 使用经过max(0, distance) 后的distance
    margin[margin > 0] = 1  # 大于0的地方设置为1
    margin[range(train_num), y] = -np.sum(margin, axis=1)  # 对于正确类别的位置，减去相应的数量
    dW = X.T.dot(margin) / train_num + 2 * reg * W
    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    return loss, dW
```



#### bool值数组索引的使用

可以用来选取一个数组中满足某些条件的元素：

- 一种用法是将原数组与某个条件对比，得到一个与原数组形状一样的bool数组，然后再用bool数组去索引原数组，会**将原数组True位置的元素选取，将False位置的元素丢弃，变成一个一维的行向量**。这个行向量实际上是原数组的一个视图，对它进行修改原数组也会被修改

  ```python
  a = np.array([[1,2], [3, 4], [5, 6]])
  
  bool_idx = (a > 2)   # Find the elements of a that are bigger than 2;
                       # this returns a numpy array of Booleans of the same
                       # shape as a, where each slot of bool_idx tells
                       # whether that element of a is > 2.
  
  print(bool_idx)      # Prints "[[False False]
                       #          [ True  True]
                       #          [ True  True]]"
  
  # We use boolean array indexing to construct a rank 1 array
  # consisting of the elements of a corresponding to the True values
  # of bool_idx
  print(a[bool_idx])  # Prints "[3 4 5 6]"
  
  # We can do all of the above in a single concise statement:
  print(a[a > 2])     # Prints "[3 4 5 6]"
  ```

- 一种用法是将bool数组乘以原数组，原数组false位置的元素会变成0，true位置的元素会不变，并且得到的数组形状也会不变

  如以下的svm loss的向量化实现方式：

  ```python
         """
      Inputs have dimension D, there are C classes, and we operate on minibatches
      of N examples.
  
      Inputs:
      - W: A numpy array of shape (D, C) containing weights.
      - X: A numpy array of shape (N, D) containing a minibatch of data.
      - y: A numpy array of shape (N,) containing training labels; y[i] = c means
        that X[i] has label c, where 0 <= c < C.
      - reg: (float) regularization strength
  
      Returns a tuple of:
      - loss as single float
      """
      y_predict = X.dot(W)
      # 使用整数数组索引从每一行选取正确类别的预测值
      true_category_pred = y_predict[range(train_num),y].reshape(-1,1)
      mask = np.ones(y_predict.shape,dtype=bool)
      # 构建bool矩阵，将正确类别的预测值处置为false
      mask[range(train_num),y] = False
      # 使用bool矩阵将正确类别的预测值剔除出去，由于得到的是行向量，所以reshape成矩阵
      false_cate_pred = y_predict[mask].reshape(500,9)
      loss = false_cate_pred - true_category_pred + 1
      # 使用条件再次构造一个bool矩阵，
      mask2 = loss > 0
  	# 将大于0的不变，将小于0的置为0，这样可以保持原形状不变，才能对每一行求和
      loss = loss * mask2
      loss = loss.sum(axis=1)
      loss = loss.mean()
  ```

#### 随机选择batch

使用random.choice从整个数据集中随机采样batch，表示从0到num_trainning之间，采样num_dev个数。replace表示是否允许重复采样，如果为True，允许重复采样；如果为False，不允许重复采样。默认为True。允许重复采样比不允许要快一些

```py
        batch_idx = np.random.choice(num_train,batch_size,True)
        X_batch,y_batch = X[batch_idx],y[batch_idx]
        # 注意！以下是错误写法！X_batch和y_batch应该是同样的索引！
        # X_batch_idx = np.random.choice(num_train,batch_size,True)
        # y_batch_idx = np.random.choice(num_train,batch_size,True)
        # X_batch,y_batch = X[X_batch_idx],y[y_batch_idx]
```

#### 多个变量指向同一个对象

下面的代码的问题在于，best_svm指向一个最好的svm，但是下一轮调参中没有重新创建一个svm对象，而是继续使用上一轮的svm对象进行训练，也就是best_svm指向的svm。

在循环中一定要记得每一轮都要刷新变量！下面的代码在循环中经过多轮迭代后beat_svm还是很差，与真正的最好的svm并不匹配，此时就要想到这个问题！

```python
learning_rates = [1e-7,1e-6,5e-5]
regularization_strengths = [1,10,1e2,1e3,1e4,1e5]

svm = LinearSVM()
for i in range(len(learning_rates)):
    for j in range(len(regularization_strengths)):
        cur_lr,cur_reg = learning_rates[i],regularization_strengths[j]
        svm.train(X_train,y_train,cur_lr,cur_reg,100,200,verbose=True)
        y_train_pred = svm.predict(X_train)
        y_valid_pred = svm.predict(X_val)
        train_acc = np.mean(y_train_pred == y_train)
        valid_acc = np.mean(y_valid_pred == y_val)
        results[(cur_lr,cur_reg)] = (train_acc,valid_acc)
        if valid_acc > best_val:
            best_val = valid_acc
            best_svm = svm
```

使用全连接层训练完后，将参数reshape成图片的形状，每个类别对应一张图片（3072 * 10），可以看出参数实际上和训练集中的图片很类似，所以**使用全连接层识别图片也是一种KNN**，使用训练集对每个类别训练出一张结合了该类别所有图片的特征的图片（即weight中该行的参数），然后测试时将输入的图片与这十张图片做比较，只不过比较的方式是内积，weight的每个参数相当于是一个权重，代表了输入图片这个位置处的像素在决定该图片是否属于该类别中的权重（因为**这个参数要与输入图片的像素相乘，所以参数值越大，则输入图片该位置处的像素对预测结果的影响就越大**）

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230914192944088.png" alt="image-20230914192944088" style="zoom:67%;" />

但是使用全连接层分类图片的准确性还是太低了，最多只能达到40%的准确度，所以需要更深的网络，以及使用卷积的神经网络

### 实现softmax

softmax的loss公式：<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230915102903026.png" alt="image-20230915102903026" style="zoom:50%;" />

softmax的梯度公式：<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230915103358879.png" alt="image-20230915103358879" style="zoom:50%;" />

```py
def softmax_loss_vectorized(W, X, y, reg):
    """
    Softmax loss function, vectorized version.

    Inputs and outputs are the same as softmax_loss_naive.
    """
    # Initialize the loss and gradient to zero.
    loss = 0.0
    dW = np.zeros_like(W)
    num_train = X.shape[0]
    #############################################################################
    # TODO: Compute the softmax loss and its gradient using no explicit loops.  #
    # Store the loss in loss and the gradient in dW. If you are not careful     #
    # here, it is easy to run into numeric instability. Don't forget the        #
    # regularization!                                                           #
    #############################################################################
    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    scores = X.dot(W)
    # 避免数值不稳定
    shift_scores = scores - np.max(scores,axis=1).reshape(-1,1)
    shift_scores = np.exp(shift_scores)
    scores_sum = shift_scores.sum(axis=1)
    softmax_output = shift_scores / scores_sum.reshape(-1,1)
    true_cate_pred = softmax_output[range(scores.shape[0]),y] 
    loss = -np.log(true_cate_pred)
    loss = loss.mean()
    loss += 0.5 * reg * np.sum(W * W)

    # 这里一定要用copy，拷贝的是softmax_output内的值，而不是softmax_ouput的指针
    # 否则修改dW会导致softmax_output也修改
    dW = softmax_output.copy()
    dW[range(dW.shape[0]),y] += -1
    dW = (X.T).dot(dW)
    dW = dW / num_train + reg * W
    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****

    return loss, dW
```

### 实现全连接层

我们需要从最基本的组件(全连接层和ReLU激活函数层)开始一点点搭建起自己的全连接神经网络。

这一部分的代码实现遵循这样的范式，包括：

- 每一种不同的神经网络层都有两个函数forward和backward需要实现
- forward函数中会使用cache来保存一些关键的参数和变量值，在backward的过程中用于计算需要更新的梯度
- 神经网络模型的参数全部在`__init__`方法中初始化并定义在一个名为params的字典中，可以方便的取用
- 模型的前向传播和反向传播都在`loss`方法中实现

神经网络又输入层输出层和中间的若干个隐层组成，这些隐层就是构成神经网络的基本组件。全连接层Fully Connected Layer是最简单的一种神经网络组件，也叫做仿射层。

#### 正向传播

全连接层也就是将所有的输入神经元和所有输出神经元进行连接，因此全连接层的正向传播的过程可以表示为

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230915122823732.png" alt="image-20230915122823732" style="zoom:67%;" />

#### 反向传播

**给定一个从输出层传递到当前全连接层的偏导结果dout**（也就是loss对下一层的偏导结果），根据链式法则，我们需要**使用当前全连接层的输出对当前层的参数求偏导，乘以dout后再传递给下一层**

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230915123246437.png" alt="image-20230915123246437" style="zoom:67%;" />

# 神经网络与反向传播

神经网络中的神经元与人脑中的神经元一样，当wx+b大于某一个阈值的时候就产生激活信号，反之就不产生。是否产生激活信号是由激活函数决定的，可以把负无穷到正无穷之间的输入压缩到0到1之间

![image-20230923162214085](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923162214085.png)

我们可以把这种神经网络叫做全连接神经网络，也叫多层感知机（一个神经元是一个感知机）

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923162927138.png" alt="image-20230923162927138" style="zoom:67%;" />

![image-20230923163812197](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923163812197.png)

![image-20230923163933312](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923163933312.png)

计算图：

![image-20230923165631698](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923165631698.png)

反向传播的计算过程：线上的绿色数字是权重，线下的红色数字是梯度

首先自己对自己求导是1

![image-20230923172039492](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923172039492.png)

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923172148765.png" alt="image-20230923172148765" style="zoom: 67%;" />

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923172205114.png" alt="image-20230923172205114" style="zoom:67%;" />

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923172227725.png" alt="image-20230923172227725" style="zoom:67%;" />

<img src="C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923172240846.png" alt="image-20230923172240846" style="zoom:67%;" />



![image-20230923164821258](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923164821258.png)

**sigmoid函数的导数是它的输出乘以一减去它的输出**，所以在计算图中，我们也可以把一些节点直接合并成sigmoid节点，用upstream 梯度乘以local的梯度即可得到sigmoid的输入的梯度

![image-20230923173325661](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923173325661.png)

所以我们能发现在反向传播的过程中的一些固定的模式：

- 乘法节点的输入的局部梯度就相当于将两边的输入互换，即获取上游梯度，并根据另一个分支的值对其缩放
- 加法节点的输入的局部梯度就是1，那么**该节点只是分发和传递和上游梯度完全相同的梯度**给相连接的输入，即该节点的输入的梯度和该节点的上游梯度完全相同。
- max节点的作用相当于是梯度路由器，将上游梯度传递给它其中的一个输入分支，剩余的分支的梯度为0

![image-20230923174707219](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923174707219.png)

![image-20230923182422014](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923182422014.png)

使用链式法则我们可以构造出模块化的代码实现：

![image-20230923181840467](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923181840467.png)

![image-20230923181911308](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923181911308.png)

同时，**在前向传播的过程中，我们需要保存下每个节点的输出值，因为在反向传播计算每个节点的梯度时会使用到**

![image-20230923182128371](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923182128371.png)

并且我们还可以发现，对梯度的偏导是输入的值，所以如果输入值越大，那么梯度的偏导就会越大，那么梯度下降中一次更新步子会非常大，导致有可能发生震荡，所以需要对数据进行预处理，将比较大的数据变小（比如取log），或者进行批量归一化

# 卷积神经网络

生物中的每个神经元对某一种特定的特征感兴趣，并且每个神经元只对图像中的一个区域感兴趣

![image-20230923195011049](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923195011049.png)

大脑中的每一部分神经元只处理一小块视觉区域（局部感受野）

![image-20230923195211188](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923195211188.png)

并且发现神经元是分层的，底层的细胞对底层的特征比较感兴趣，越到高级，大脑就会对底层的特征进行融合和特化

![image-20230923195335418](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923195335418.png)

在终端计算就叫边缘计算，比如无人驾驶

![image-20230923201425123](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230923201425123.png)

卷积的输出公式：（W- F+ 2 P) / S+ 1，F是感受野，P是填充（上下左右各填充P），S是步长，W是输入的宽度

当步长是1时将0填充设置为：P=(F−1)/2可以让输入和输出的大小相同

池化公式：

![image-20230924121600367](C:\Users\李博\Desktop\mynotes\ai\cs231n.assets\image-20230924121600367.png)

在实践中发现的池化层通常只有两种：

- F= 3 , S= 2（也称为重叠池）
- 更常见的是F= 2 , S= 2

太大的池化层破坏力太强

max节点的反向传播仅仅将上游梯度传播到最大的输入，所以在池化层的前向传播过程中通常会跟踪最大的输入的索引，以便在反向传播时更高效

最常见的 ConvNet 架构遵循以下模式：

```
INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC
```

其中`*`表示重复，`N >= 0`（通常是`N <= 3`），`M >= 0`，`K >= 0`通常是`K < 3`

- 输入**层**（包含图像）应该可以被 2 整除很多次。常见的数字包括 32（例如 CIFAR-10）、64、96（例如 STL-10）或 224（例如常见的 ImageNet ConvNet）、384 和 512。

- 卷积**层**应该使用小过滤器（例如 3x3 或最多 5x5），使用步长S= 1，最重要的是，用零填充体积，以使卷积层不会改变输入的空间维度。比如，F=3，P=1；F=5，P=2 。如果必须使用更大的滤波器尺寸（例如 7x7 左右），则通常只在查看输入图像的第一个卷积层上看到这种情况。
  - 使用填充除了可以不改变输入的空间维度之外，还可以提高性能，避免每次卷积之后，体积的大小大量减少，并且边界处的信息将被过快地冲走

- 池**层**负责对输入的空间维度进行下采样。最常见的设置是使用具有 2x2 感受野的最大池化（即F= 2），步幅为 2（即S= 2）。请注意，这会丢弃输入体积中 75% 的激活（由于宽度和高度均下采样 2）

卷积神经网络的内存和参数使用情况（以VGG为例）：

```
INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864
POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456
POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0
FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448
FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216
FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000

TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)
TOTAL params: 138M parameters
```

可以看到，**卷积神经网络的内存占用（以及计算时间）主要是前向传播和反向传播的中间结果**，而且主要在早期的卷积层中。

- 因为卷积层输出的中间结果往往会非常大（由于卷积核的大小通常是3或5，所以输出的形状几乎不变，但是通道数往往非常大，如64）（这些中间结果之所以被保留是因为反向传播需要他们），同时反向传播时还要对每个中间结果都计算出对应的梯度。

当然，参数也要占一部分的内存空间（包括参数的梯度），但是这些是小头

除此之外，大部分的参数在最后的全连接层中，因为卷积核共享参数，所以相比全连接层，卷积层的参数很少。
