# OSTEP学习笔记

## 第二章、操作系统介绍

有一类软件负责让程序运行变得容易（甚至允许你同时运行多个程序），允许程序共享内存，让程序能够与设备交互，以及其他类似的有趣的工作。这些软件称为**操作系统（Operating System，OS）**，因为它们负责确保系统既易于使用又正确高效地运行。

要做到这一点（指同时运行多个程序、允许程序共享内存等），操作系统主要利用**虚拟化（virtualization）**技术。 

- **操作系统将物理（physical）资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式**。因此，我们有时将操作系统称为虚拟机（virtual machine）。

  - 虚拟化CPU，让许多程序同时运行（从而**共享CPU**）
  - 虚拟化内存，让许多程序可以同时访问自己的指令和数据，在相同的地址空间中运行（从而**共享内存**），
  - 虚拟化磁盘，让许多程序访问设备（从而**共享磁盘**等）

  每个 CPU、内存和磁盘都是系统的资源（resource）， 因此操作系统扮演的主要角色就是管理（manage）这些资源。所以操作系统有时被称为**资源管理器（resource manager）**。

为了让用户可以告诉操作系统做什么，从而利用虚拟机的功能（如运行程序、分配内存或访问文件），操作系统还提供了一些接口（API），供你调用（即**系统调用**）。由于操作系统提供这些调用 来运行程序、访问内存和设备，甚进行其他相关操作，我们有时也会说操作系统为应用程序提供了一个**标准库（standard library）**。

### 2.1 虚拟化CPU

操作系统负责提供系统拥有非常多的虚拟 CPU 的假象。**将单个 CPU（或其中一小部分）转换为看似无限数量的 CPU， 从而让许多程序看似同时运行**，这就是所谓的**虚拟化 CPU（virtualizing the CPU）**

### 2.2 虚拟化内存 

我们运行同一个程序的多个实例会看到，每个正在运行的程序都在相同的地址（00200000）处分配了内存，但每个似乎都独立更新了 00200000 处的值！就好像每个正在运行的程序都有自己的私有内存，而不是 与其他正在运行的程序共享相同的物理内存。

这正是操作系统**虚拟化内存（virtualizing memory）**时发生的情况。每个进程访问自己的私有虚拟地址空间（virtual address space）（有时称为地址空间，address space）， **操作系统以某种方式映射到机器的物理内存上**。

### 2.3 并发

**并发问题首先出现在操作系统本身中**，在虚拟化中，操作系统同时处理很多事情，首先运行一个进程，然后 再运行一个进程，等等。但是并发问题不再局限于操作系统本身，**现代多线程（multi-threaded） 程序也存在相同的问题**。

### 2.5 设计目标

现在你已经了解了操作系统实际上做了什么：

- 它取得 CPU、内存或磁盘等物理资源 （resources），并对它们进行虚拟化（virtualize）。
- 它处理与并发（concurrency）有关的麻烦且棘手的问题。
- 它持久地（persistently）存储文件，从而使它们长期安全。

我们需要在应用程序之间以及在 OS 和应用程序之间提供保护（protection）。因为 我们希望让许多程序同时运行，所以要确保一个程序的恶意或偶然的不良行为不会损害其 他程序。我们当然不希望应用程序能够损害操作系统本身（因为这会影响系统上运行的所 有程序）。保护是操作系统基本原理之一的核心，这就是**隔离（isolation）**，让进程彼此隔离是保护的关键。

## 4、抽象：进程

**进程就是运行中的程序**。程序本身是没有生命周期的，它只是存在磁盘上面的一些指令（也可能 是一些静态数据）。是**操作系统让这些字节运行起来，将静态的程序转化为进程**。

虚拟化（virtualizing）CPU：通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟 CPU 的假象

实现 CPU 的虚拟化，要实现得好，操作系统就需要一些低级机制以及一些高级智能：

- 低级机制称为**机制（mechanism）**。机制是一些低级方法或协议，实现了所需的功能。
- 在这些机制之上，操作系统中有一些智能以**策略（policy）**的形式存在。策略是在操作系统内**做出某种决定的算法**

### 进程创建

任何能够同时运行多个程序的操作系统当然都会有类似**进程列表（process list）**这样的结构，以便跟踪系统中正在运行的所有程序。**进程控制块（Process Control Block，PCB）**是存储关于进程的信息的**个体**结构

![image-20210822105414965](https://raw.githubusercontent.com/BoL0150/image2/master/image-20210822105414965.png)

![image-20210822105450432](https://raw.githubusercontent.com/BoL0150/image2/master/image-20210822105450432.png)

![image-20210822105631116](https://raw.githubusercontent.com/BoL0150/image2/master/image-20210822105631116.png)

`-e main`表示链接的入口是main函数

## 并发

对于确定的数据集，某进程指令执行地址序列是确定的 ，称为进程的**逻辑控制流**。对于**单处理器系统**，进程会**轮流**使用处理器，即**处理器的物理控制流由多个逻辑控制流组成**。

<img src="https://raw.githubusercontent.com/BoL0150/image2/master/image-20210802203329929.png" alt="image-20210802203329929" style="zoom:67%;" />

**逻辑控制流不会因被其他进程打断而改变， 还能回到原被打断的“断点”处继续执行**。不同进程的逻辑控制流在时间上**交错或重叠**的情况称为**并发（concurrency）**

注意！只要两个进程的逻辑流在时间上重叠，则它们就是并发流。如果并发流在不同核或计算机上运行，则成为并行流。**并行流属于并发流，区别只在于是否在同一处理器上运行**。

![image-20210822220832373](https://raw.githubusercontent.com/BoL0150/image2/master/image-20210822220832373.png)

### 线程

本章为**单个运行进程**提供的新抽象：线程（thread）：多个执行流并发/并行执行，并且它们**共享虚拟内存**。

- 两个执行流共享代码和所有全局变量（数据、堆区）
- 线程之间指令执行顺序是不确定的

经典观点是一个程序只有 一个执行点（一个程序计数器，用来存放要执行的指令），但多线程（multi-threaded）程序会有多个执行点（多个程序计数器，每个都用于取指令和执行）。换一个角度来看，**每个线 程类似于独立的进程，只有一点区别：它们共享地址空间，从而能够访问相同的数据**。

线程与进程相似的地方：

- 每个线程有一个程序计数器（PC），记录程序从哪里获取指令。
- 每个线程有自己的一组用于计算的寄存器。
- 所以，如果有两个线程运行在一个处理器上，从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切 换（context switch）。线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们 将状态保存到**进程控制块（Process Control Block，PCB）**。现在，我们需要一个或多个**线程控制块（Thread Control Block，TCB）**，保存每个线程的状态。

但是，与进程相比，线程之间的上下文切换有一点主要区别：**地址空间保持不变（即不需要切换当前使用的页表）**。

线程和进程之间的另一个主要区别在于栈：在简单的传统进程地址空间模型（我们现在可以称之为单线程（single-threaded）进程） 中，只有一个栈，通常位于地址空间的底部。**在多线程的进程中，每个线程独立运行，每个线程都有一个栈**。所有位于栈上的变量、 参数、返回值和其他放在栈上的东西，将被放置在有时称为**线程本地（thread-local）**存储的 地方，即相关线程的栈。

<img src="https://raw.githubusercontent.com/BoL0150/image2/master/image-20210822230514902.png" alt="image-20210822230514902" style="zoom:67%;" />

也就是说，**线程之间共享地址空间（但是每个线程都有自己的栈。即共享代码和全局变量，不共享局部变量），不共享寄存器，程序计数器**。

